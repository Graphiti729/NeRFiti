#llff:
#  factor: 8 # load_diff._minify
#  recenter: True
#  bd_factor: .75
#  spherify: True
#  llffhold: 8 # will take every 1/N images as LLFF test set, paper uses 8
#  no_ndc: True # 'do not use normalized device coordinates (set for non-forward facing scenes)
#  lindisp: True # sampling linearly in disparity rather than depth
#

synthetic:
  data_type: nerf_synthetic
  dataset: chair # options : chair, drums, ficus, hotdog, lego, materials, mic, ship
  run_type: train # options : train, val ,test
  path_zflat: False # regarding render_poses(poses for test img), choose spiral or path
  factor: 8
  bd_factor: .75
  recenter : True
  spherify : True
  llffhold: 8 # will take every 1/N images as LLFF test set, paper uses 8
  no_ndc: True # 'do not use normalized device coordinates (set for non-forward facing scenes)

llff:
  data_type: nerf_llff_data
  dataset: fern # options : fern, flower, fortress, horns, leaves, orchids, room, trex

  run_type: train # options : train, val ,test
  path_zflat: False # regarding render_poses(poses for test img), choose spiral or path
  factor: 8
  bd_factor: .75
  recenter : True
  spherify : True
  llffhold: 8 # will take every 1/N images as LLFF test set, paper uses 8
  no_ndc: True # 'do not use normalized device coordinates (set for non-forward facing scenes)
  lindisp: True # sampling linearly in disparity rather than depth


embed:
  include_input: True
  input_dims : 3
  log_sampling: True


rendering:
  multires: 10 # 'log2 of max freq for positional encoding (3D location)'
  multires_views: 4 # 'log2 of max freq for positional encoding (2D direction)'
  raw_noise_std: 0. # 'std dev of noise added to regularize sigma_a output, 1e0 recommended'
  use_viewdirs: False # use full 5D input instead of 3D
  N_samples: 64 # number of coarse samples per ray
  N_importance: 0 # number of additional fine samples per ray
  perturb: 1. # set to 0. for no jitter, 1. for jitter
  i_embed: 0 # set 0 for default positional encoding, -1 for none

  render_test: True # render the test set instead of render_poses path
  render_only: False # do not optimize, reload weights and render out render_poses path
  render_factor: 0 #downsampling factor to speed up rendering, set 4 or 8 for fast preview

model:
  layer_num: 8 # Originalnetdepth: 8 # layers in network
  hidden_feature : 256 # netwidth: 256 # channels per layer
  layer_num_fine : 8 # netdepth_fine: 8 # layers in fine network
  hidden_feature_fine : 256 # netwidth_fine: 256 # channels per layer in fine network
  N_rand: 4096 # 32*32*4, batch size (number of random rays per gradient step)

  lrate: 5.0E-4 # learning rate
  lrate_decay: 250 # exponential learning rate decay (in 1000s)
  lrate_schedule_gamma: 0.1
  N_iters: 30 # 10000

  chunk: 32768 # 1024*32, number of rays processed in parallel, decrease if running out of memory. 5GB used
#  chunk: 40 # 1024*32, number of rays processed in parallel, decrease if running out of memory
  # netchunk: 65536 # 1024*64, number of pts sent through network in parallel, decrease if running out of memory
  netchunk: 20 # 1024*64, number of pts sent through network in parallel, decrease if running out of memory
  no_batching: True # only take random rays from 1 image at a time
  no_reload: True # do not reload weights from saved ckpt
  ft_path: None # specific weights npy file to reload for coarse network
  random_seed: None, # fix random seed for repeatability

  precrop_iters: 0 # 'number of steps to train on central crops'
  precrop_frac: .5 # fraction of img taken for central crops

blender:
  white_bkgd: True # set to render synthetic data on a white bkgd (always use for dvoxels)