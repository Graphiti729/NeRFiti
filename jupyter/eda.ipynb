{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\I571927\\\\PycharmProjects\\\\Nerf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set: fern, flower, fortress, norns, leaves, orchids, room, trex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'flower'\n",
    "datadir = f'./dataset/nerf_llff_data/{dataset}'\n",
    "factor = 8\n",
    "bd_factor=.75\n",
    "path_zflat=False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _load_data\n",
    "\n",
    "src.load_llff에서 사용하는 pipeline을 refactoring하고 있는 것\n",
    "\n",
    "크게 factor가 주어졌을 때와 그렇지 않을때를 구분해야할 것으로 보이고 factor가 주어졌을 때 진행되는 update는 다음과 같다.\n",
    "\n",
    "- minify : 원본 이미지를 factor에 맞춰서 mogrify로 줄여주는 과정\n",
    "- update_pose_bd : factor만큼 f를 조정하고, hw는 mogrify로 줄여진 크기를 사용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _load_data (Phase 1)\n",
    "\n",
    "I: \n",
    "- datadir\n",
    "- factor: minify할 때 사용. 어떤 이미지를 불러올지 결정하는 것\n",
    "\n",
    "O: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_sh\n",
    "\n",
    "원래 img0라고 하던 것을 img_path로 정정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I571927\\AppData\\Local\\Temp\\ipykernel_21688\\2227507593.py:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  sh = imageio.imread(img_path).shape\n"
     ]
    }
   ],
   "source": [
    "img_path = [os.path.join(datadir, 'images', f) for f in sorted(os.listdir(os.path.join(datadir, 'images'))) \\\n",
    "        if f.endswith('JPG') or f.endswith('jpg') or f.endswith('png')][0]\n",
    "sh = imageio.imread(img_path).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3024, 4032, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minify\n",
    "\n",
    "이건 이미지의 가로, 세로, factor 크기를 명시했을 때 aspect ratio를 맞춰서 줄여주고 image*로 만든 폴더에 옮겨두는 것에 해당한다!\n",
    "\n",
    "subprocess로 image를 resize를 하게 하며  mogrify를 사용해서 진행한다.\n",
    "\n",
    "현재 데이터 셋에서는 이미 해당도가 맞춰서 정리되어 있기 때문에 구현하지 않도록 하고, 추후에 변경이 필요하다면 offline으로 처리하도록 한다\n",
    "\n",
    "기존 코드에서는 factor만 알려주는 형태로 구현되어 있다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chck_dir\n",
    "\n",
    "이건 알려준 shape에 해당하는 이미지가 있는지 없는지 확인\n",
    "\n",
    "I\n",
    "- factor_list: [factor]로 단순히 list로 factor를 받은 것 <br>\n",
    "O: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_list = [factor]\n",
    "resolutions = []\n",
    "\n",
    "needtoload = False\n",
    "for r in factor_list:\n",
    "    imgdir = os.path.join(datadir, 'images_{}'.format(r))\n",
    "    if not os.path.exists(imgdir):\n",
    "        needtoload = True\n",
    "for r in resolutions:\n",
    "    imgdir = os.path.join(datadir, 'images_{}x{}'.format(r[1], r[0]))\n",
    "    if not os.path.exists(imgdir):\n",
    "        needtoload = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copy\n",
    "from subprocess import check_output\n",
    "\n",
    "imgdir = os.path.join(datadir, 'images')\n",
    "imgs = [os.path.join(imgdir, f) for f in sorted(os.listdir(imgdir))]\n",
    "imgs = [f for f in imgs if any([f.endswith(ex) for ex in ['JPG', 'jpg', 'png', 'jpeg', 'PNG']])]\n",
    "imgdir_orig = imgdir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _load_data(Phase 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_img_path\n",
    "\n",
    "factor만 조정한다면 sfx는 _factor로 된 폴더를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfx = f\"_{factor}\"\n",
    "\n",
    "imgdir = os.path.join(datadir, 'images' + sfx)\n",
    "img_paths = [os.path.join(imgdir, f) for f in sorted(os.listdir(imgdir)) if\n",
    "                f.endswith('JPG') or f.endswith('jpg') or f.endswith('png')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_pose_bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_arr = np.load(os.path.join(datadir, 'poses_bounds.npy'))\n",
    "poses = poses_arr[:, :-2].reshape([-1, 3, 5]).transpose([1, 2, 0])\n",
    "bds = poses_arr[:, -2:].transpose([1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 17)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 34)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (34, 17)->(34,15)->(34,3,5)->(3,5,34)\n",
    "poses_arr[:, :-2].reshape([-1, 3, 5]).transpose([1, 2, 0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 34)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses_arr[:, -2:].transpose([1, 0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.01294097 0.99962852 0.02398638]\n",
      "1 [ 0.99991381 -0.01288403 -0.00252655]\n",
      "2 [-0.00221657  0.02401701 -0.99970909]\n",
      "3 [-5.55752123 -2.23216201  1.38032517]\n",
      "4 [3024.         4032.         3575.05860595]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i, poses[:,i,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update_pose_bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I571927\\AppData\\Local\\Temp\\ipykernel_21688\\2947389849.py:2: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  sh = imageio.imread(img_paths[0]).shape\n"
     ]
    }
   ],
   "source": [
    "# hwf를 update하는 것으로 factor를 지정했을 때 업데이트 하게 된다.\n",
    "sh = imageio.imread(img_paths[0]).shape\n",
    "poses[:2, 4, :] = np.array(sh[:2]).reshape([2, 1])\n",
    "poses[2, 4, :] = poses[2, 4, :] * 1. / factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.01294097 0.99962852 0.02398638]\n",
      "1 [ 0.99991381 -0.01288403 -0.00252655]\n",
      "2 [-0.00221657  0.02401701 -0.99970909]\n",
      "3 [-5.55752123 -2.23216201  1.38032517]\n",
      "4 [378.         504.         446.88232574]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i, poses[:,i,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I571927\\AppData\\Local\\Temp\\ipykernel_21688\\1962279215.py:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  return imageio.imread(f, ignoregamma=True)\n"
     ]
    }
   ],
   "source": [
    "def imread(f):\n",
    "    if f.endswith('png'):\n",
    "        return imageio.imread(f, ignoregamma=True)\n",
    "    else:\n",
    "        return imageio.imread(f)\n",
    "\n",
    "imgs = imgs = [imread(f)[..., :3] / 255. for f in img_paths]\n",
    "imgs = np.stack(imgs, -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update roation matrix\n",
    "\n",
    "여기에서는 다시 (# image, xyz, # vector)로 재구성 됨\n",
    "\n",
    "이렇게 한 이유는 pose가 [-y, x, z] 로 구성되어 있기 때문이다!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct rotation matrix ordering and move variable dim to axis 0\n",
    "# xyz * (ori1, ori0, ori2, ori3, hwf)\n",
    "poses = np.concatenate([poses[:, 1:2, :], -poses[:, 0:1, :], poses[:, 2:, :]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.99991381 -0.01288403 -0.00252655]\n",
      "1 [-0.01294097 -0.99962852 -0.02398638]\n",
      "2 [-0.00221657  0.02401701 -0.99970909]\n",
      "3 [-5.55752123 -2.23216201  1.38032517]\n",
      "4 [378.         504.         446.88232574]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i, poses[:, i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에서 # image를 맨 앞으로 옮기게 됨\n",
    "poses = np.moveaxis(poses, -1, 0).astype(np.float32)\n",
    "imgs = np.moveaxis(imgs, -1, 0).astype(np.float32)\n",
    "images = imgs\n",
    "bds = np.moveaxis(bds, -1, 0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.9999138  -0.01288403 -0.00252655]\n",
      "1 [-0.01294096 -0.99962854 -0.02398638]\n",
      "2 [-0.00221657  0.02401701 -0.99970907]\n",
      "3 [-5.5575213 -2.232162   1.3803252]\n",
      "4 [378.      504.      446.88232]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i, poses[0, :, i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale if bd_factor is provided\n",
    "sc = 1. if bd_factor is None else 1. / (bds.min() * bd_factor)\n",
    "poses[:, :3, 3] *= sc\n",
    "bds *= sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.9999138  -0.01288403 -0.00252655]\n",
      "1 [-0.01294096 -0.99962854 -0.02398638]\n",
      "2 [-0.00221657  0.02401701 -0.99970907]\n",
      "3 [-0.32825887 -0.13184421  0.08152987]\n",
      "4 [378.      504.      446.88232]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i, poses[0, :, i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recenter\n",
    "\n",
    "본 코드에서는 기본값으로 recenter를 하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return x / np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_viewmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 3, 5)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwf = poses[0, :3, -1:]\n",
    "\n",
    "center = poses[:, :3, 3].mean(0)\n",
    "vec2 = normalize(poses[:, :3, 2].sum(0))\n",
    "up = poses[:, :3, 1].sum(0)\n",
    "\n",
    "z, up, pos = vec2, up, center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_viewmatrix(z, up, pos):\n",
    "    vec2 = normalize(z)\n",
    "    vec1_avg = up\n",
    "    vec0 = normalize(np.cross(vec1_avg, vec2))\n",
    "    vec1 = normalize(np.cross(vec2, vec0))\n",
    "    m = np.stack([vec0, vec1, vec2, pos], 1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2 = normalize(z)\n",
    "vec1_avg = up\n",
    "vec0 = normalize(np.cross(vec1_avg, vec2))\n",
    "vec1 = normalize(np.cross(vec2, vec0))\n",
    "viewmatrix = np.stack([vec0, vec1, vec2, pos], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewmatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99990654,  0.00250978, -0.01343402], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewmatrix[:, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_c2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2w = np.concatenate([viewmatrix, hwf], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2w.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recenter_poses 최종"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_ = poses + 0\n",
    "bottom = np.reshape([0, 0, 0, 1.], [1, 4])\n",
    "c2w = np.concatenate([c2w[:3, :4], bottom], -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99990654,  0.00250978, -0.01343402,  0.        ])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2w[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지에 대해서 각각 만들어 줌.\n",
    "bottom = np.tile(np.reshape(bottom, [1, 1, 4]), [poses.shape[0], 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 1, 4)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = np.concatenate([poses[:, :3, :4], bottom], -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 4, 4)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "카메라 모델\n",
    "![img](./assets/pipeline-02-typical_perspective_model.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 이미지에서 M(3,4)가 기존의 c2w에서 view matrix의 역할이었던 것\n",
    "poses = np.linalg.inv(c2w) @ poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 4, 4)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.94865284e-03, 6.87575154e-03, 2.62866117e-04, 1.00000000e+00])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 내가 보았을 때 recenter의 의미가 결과적으로 P에 M^{-1}을 행렬곱한 것을 poses로 사용하는 것 같다.\n",
    "poses_[:, :3, :4] = poses[:, :3, :4]\n",
    "poses = poses_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_ = poses + 0\n",
    "bottom = np.reshape([0, 0, 0, 1.], [1, 4])\n",
    "c2w = np.concatenate([c2w[:3, :4], bottom], -2)\n",
    "bottom = np.tile(np.reshape(bottom, [1, 1, 4]), [poses.shape[0], 1, 1])\n",
    "poses = np.concatenate([poses[:, :3, :4], bottom], -2)\n",
    "\n",
    "poses = np.linalg.inv(c2w) @ poses\n",
    "poses_[:, :3, :4] = poses[:, :3, :4]\n",
    "poses = poses_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 4, 4)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pose 바뀌기 전<br>\n",
    "![img](./assets/eda-01-pose%20state%201.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.99991585 -0.01279143 -0.00222709  0.        ]\n",
      "1 [-0.01279741 -0.99991444 -0.00268797  0.        ]\n",
      "2 [-0.00219251  0.00271624 -0.9999938   0.        ]\n",
      "3 [-0.34415161 -0.1301463   0.08449194  1.        ]\n"
     ]
    }
   ],
   "source": [
    "# 여기에서는 hwf가 빠지게 된다.\n",
    "for i in range(4):\n",
    "    print(i, poses[0, :, i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get_render_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0025097 , -0.99994036,  0.01062915])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2w = np.concatenate([viewmatrix, hwf], 1)\n",
    "\n",
    "## Get spiral\n",
    "# Get average pose\n",
    "up = normalize(poses[:, :3, 1].sum(0))\n",
    "\n",
    "up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get focus depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a reasonable \"focus depth\" for this dataset\n",
    "# 이건 그냥 heuristic인지 아닌지 확인해봐야 할 듯\n",
    "close_depth, inf_depth = bds.min() * .9, bds.max() * 5.\n",
    "dt = .75\n",
    "mean_dz = 1. / (((1. - dt) / close_depth + dt / inf_depth))\n",
    "focal = mean_dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.200000035762787,\n",
       " 65.7046365737915,\n",
       " 0.20833332712451635,\n",
       " 0.011414719555714926)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_depth, inf_depth, (1. - dt) / close_depth, dt / inf_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get radii for spiral path\n",
    "shrink_factor = .8\n",
    "zdelta = close_depth * .2\n",
    "\n",
    "# 이건 말 그대로 translation을 말하는 것으로 보인다. 즉 이미지를 찍은 camera의 pose의 translation vector\n",
    "tt = poses[:, :3, 3]  # ptstocam(poses[:3,3,:].T, c2w).T\n",
    "rads = np.percentile(np.abs(tt), 90, 0)\n",
    "c2w_path = c2w\n",
    "N_views = 120\n",
    "N_rots = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34, 3), array([0.28753879, 0.14944784, 0.08435769]))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.shape, rads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get spiral path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_path_spiral(c2w, up, rads, focal, zdelta, zrate, rots, N):\n",
    "    render_poses = []\n",
    "    rads = np.array(list(rads) + [1.])\n",
    "    hwf = c2w[:, 4:5]\n",
    "\n",
    "    for theta in np.linspace(0., 2. * np.pi * rots, N + 1)[:-1]:\n",
    "        c = np.dot(c2w[:3, :4], np.array([np.cos(theta), -np.sin(theta), -np.sin(theta * zrate), 1.]) * rads)\n",
    "        z = normalize(c - np.dot(c2w[:3, :4], np.array([0, 0, -focal, 1.])))\n",
    "        render_poses.append(np.concatenate([get_viewmatrix(z, up, c), hwf], 1))\n",
    "    return render_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.28753879, 0.14944784, 0.08435769, 1.        ]),\n",
       " array([[378.     ],\n",
       "        [504.     ],\n",
       "        [446.88232]], dtype=float32))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rots=N_rots\n",
    "N=N_views\n",
    "zrate=.5\n",
    "\n",
    "# Generate poses for spiral path\n",
    "# render_poses = render_path_spiral(c2w_path, up, rads, focal, zdelta, zrate=.5, rots=N_rots, N=N_views)\n",
    "\n",
    "render_poses = []\n",
    "rads = np.array(list(rads) + [1.])\n",
    "hwf = c2w[:, 4:5]\n",
    "\n",
    "rads, hwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 4), (4,))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = 0\n",
    "c2w[:3, :4].shape, np.array([np.cos(theta), -np.sin(theta), -np.sin(theta * zrate), 1.]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.28753879, -0.        , -0.        ,  1.        ])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.cos(theta), -np.sin(theta), -np.sin(theta * zrate), 1.]) * rads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_poses = []\n",
    "for theta in np.linspace(0., 2. * np.pi * rots, N + 1)[:-1]:\n",
    "    # theta만큼 돌아가면서 X_{4x1}을 알려주고 이에 따라서 위치를 camera space에 올리기\n",
    "    # 우선 np.array로 만드는 것은 world frame에서의 homogeneous coordi\n",
    "    # 그리고 rad는 camera matrix의 translation에 해당\n",
    "    # 결과적으로 x, y, z축으로 [cos, -sin, -sin(rate)]만큼 회전시켜 spiral이 나오게 되는 것\n",
    "    # 그리고 이를 translation과 곱하니 원래 pixel이 출발한 위치에서 변화가 되는 것이다.\n",
    "    # 이를 camera matrix(Intri * Extri)을 곱하게 되면 그 변화가 image plane에서의 좌표가 나오게 된다.\n",
    "    c = np.dot(c2w[:3, :4], np.array([np.cos(theta), -np.sin(theta), -np.sin(theta * zrate), 1.]) * rads)\n",
    "\n",
    "    # 의미 그대로 camera space상에서 z축을 말한다.\n",
    "    # x,y 축 값은 0으로 없어지게 되고 z축 값만 dot product으로 남게 되니 camera coordi 에서의 z축 방향만 남음\n",
    "    z = normalize(c - np.dot(c2w[:3, :4], np.array([0, 0, -focal, 1.])))\n",
    "    render_poses.append(np.concatenate([get_viewmatrix(z, up, c), hwf], 1))\n",
    "render_poses = np.array(render_poses).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3, 5)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_poses.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "667fee2431e2e676278eec3998e36f78c2343c99510bed9870ca4c4b4458ddc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
